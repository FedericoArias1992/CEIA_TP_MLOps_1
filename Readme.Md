# ğŸš— PredicciÃ³n de Precios de Autos Usados con Playwright, Airflow y MLflow

Este proyecto implementa un flujo de trabajo completo de Machine Learning enfocado en la predicciÃ³n del precio de autos usados en Bolivia. La soluciÃ³n automatiza desde el scrapping de datos hasta el despliegue del mejor modelo en producciÃ³n utilizando Apache Airflow como orquestador y MLflow para el tracking y versionado de modelos.

## ğŸ§  Objetivo del Proyecto

1. **Scrapear** datos de autos usados desde una plataforma online.
2. **Limpiar** los datos descargados de forma incremental.
3. **Preprocesar** concatenar descargas anteriores, procesar variables categÃ³ricas, valores faltantes y construir los datasets `X_train`, `y_train`.
4. **Entrenar** tres modelos de regresiÃ³n y promover el mejor a producciÃ³n.
5. **Realizar predicciones** con el modelo en producciÃ³n.

## ğŸ§° TecnologÃ­as utilizadas

| Herramienta         | DescripciÃ³n                                           |
|---------------------|-------------------------------------------------------|
| **Apache Airflow**  | Orquestador de tareas para flujos de trabajo diarios |
| **MLflow**          | Seguimiento, versionado y registro de modelos ML     |
| **Docker Compose**  | Entorno reproducible con contenedores                |
| **Pandas & Scikit-learn** | Procesamiento de datos y entrenamiento de modelos |
| **CatBoost / SVR**  | Modelos adicionales para comparaciÃ³n de desempeÃ±o    |

## âš™ï¸ Estructura del Proyecto
- â”œâ”€â”€ airflow/
- â”‚ â”œâ”€â”€ dags/
- â”‚ â”‚ â””â”€â”€ scraping_autopia_dag.py
- â”‚ â”‚ â””â”€â”€ entrenamiento_modelos_regresion_dag.py
- â”‚ â”‚ â””â”€â”€ prediccion_modelo_produccion_dag.py
- â”‚ â”œâ”€â”€â”€â”€ utils/
- â”‚ â”‚ â””â”€â”€ scraping_autopia.py
- â”‚ â”œâ”€â”€â”€â”€ data/
- â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€ prediccion/
- â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€ processed/
- â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€ raw/
- â”‚ â”œâ”€â”€ plugins/
- â”‚ â”œâ”€â”€ config/
- â”‚ â””â”€â”€ secrets/
- â”œâ”€â”€ dockerfiles/
- â”‚ â””â”€â”€ airflow/ # Imagen extendida con dependencias
- â”œâ”€â”€ mlruns/ # Volumen persistente de MLflow
- â”œâ”€â”€ data/
- â”‚ â””â”€â”€ processed/ # Archivos .pkl listos para entrenamiento
- â”œâ”€â”€ docker-compose.yaml
- â”œâ”€â”€ requirements.txt
- â””â”€â”€ README.md

### ğŸ” Flujo completo de DAGs

1. ### `scraping_autopia_dag` (Ejecutado manual o programado)
   - Ejecuta un script que scrapea datos desde [autopia.com.bo](https://autopia.com.bo).
   - Guarda los datos en formato `.csv` en la carpeta `data/raw/`.
   - Una vez finalizado, **activa automÃ¡ticamente** el siguiente DAG.
   - _Observacion:_ Tarda + 110 minutos en descargar todos los registros de la pagina.

2. ### `entrenamiento_modelos_regresion_dag` (Ejecutado automÃ¡ticamente tras scraping o de forma diaria)
   - **Carga del dataset** reciÃ©n scrapeado.
   - **Preprocesamiento**:
     - Limpieza de columnas como `price`, `motor`, etc.
     - `TargetEncoder` para codificar variables categÃ³ricas (`marca`, `tipo`).
     - Map de variables binarias (`transmisiÃ³n`).
   - **Entrenamiento de modelos**:
     - `RandomForestRegressor`
     - `CatBoostRegressor`
     - `SVR`
   - **EvaluaciÃ³n** con `MAE` y registro de mÃ©tricas y modelos en **MLflow**.
   - **PromociÃ³n automÃ¡tica** del mejor modelo al stage `"Production"`.
   - **Archivado del modelo anterior** como `"Staging"` si existÃ­a.
   - Al finalizar, **dispara automÃ¡ticamente** el DAG de predicciÃ³n.

3. ### `prediccion_modelo_produccion_dag`
   - Carga el modelo en stage `"Production"` desde **MLflow**.
   - Prepara nuevas muestras o clientes para predicciÃ³n.
   - Genera predicciones y las guarda en el directorio `data/predicciones/`.

## ğŸ” EjecuciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/FedericoArias1992/CEIA_TP_MLOps_1.git
```
# 2. Crear y dar permisos a los volÃºmenes
```bash
mkdir -p mlruns
sudo chown -R 50000:0 mlruns
```

# 3. Levantar el entorno completo
```bash
docker-compose up --build -d
```
Para detenerlo:
```Bash
docker compose down
```

Para detenerlo y eliminar todo:
```Bash
docker compose down --rmi all --volumes
```

# 4. Acceder a interfaces
Airflow UI: http://localhost:8080

MLflow UI: http://localhost:5000


```Bash
docker compose up
```

### Para editar desde VSC: sudo chown -R federico:federico /home/federico/Proyectos/CEIA/MLops1/
### Si da error de escritura sobre el path: sudo chown -R 50000:0 ./mlruns
