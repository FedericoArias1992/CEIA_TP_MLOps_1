# ğŸš— PredicciÃ³n de Precios de Autos Usados con Airflow y MLflow

Este proyecto implementa un flujo de trabajo completo de Machine Learning enfocado en la predicciÃ³n del precio de autos usados en Bolivia. La soluciÃ³n automatiza desde el scrapping de datos hasta el despliegue del mejor modelo en producciÃ³n utilizando Apache Airflow como orquestador y MLflow para el tracking y versionado de modelos.

## ğŸ§  Objetivo del Proyecto

1. **Scrapear** datos de autos usados desde una plataforma online.
2. **Limpiar** los datos descargados de forma incremental.
3. **Preprocesar** variables categÃ³ricas, valores faltantes y construir los datasets `X_train`, `y_train`.
4. **Entrenar** tres modelos de regresiÃ³n y promover el mejor a producciÃ³n.
5. **Realizar predicciones** con el modelo en producciÃ³n.

## ğŸ§° TecnologÃ­as utilizadas

| Herramienta         | DescripciÃ³n                                           |
|---------------------|-------------------------------------------------------|
| **Apache Airflow**  | Orquestador de tareas para flujos de trabajo diarios |
| **MLflow**          | Seguimiento, versionado y registro de modelos ML     |
| **Docker Compose**  | Entorno reproducible con contenedores                |
| **Pandas & Scikit-learn** | Procesamiento de datos y entrenamiento de modelos |
| **CatBoost / SVR**  | Modelos adicionales para comparaciÃ³n de desempeÃ±o    |

## âš™ï¸ Estructura del Proyecto
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â””â”€â”€ entrenamiento_modelos_regresion_dag.py
â”‚ â”œâ”€â”€ plugins/
â”‚ â”œâ”€â”€ config/
â”‚ â””â”€â”€ secrets/
â”œâ”€â”€ dockerfiles/
â”‚ â””â”€â”€ airflow/ # Imagen extendida con dependencias
â”œâ”€â”€ mlruns/ # Volumen persistente de MLflow
â”œâ”€â”€ data/
â”‚ â””â”€â”€ processed/ # Archivos .pkl listos para entrenamiento
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## ğŸ§ª Flujo de trabajo orquestado

### DAG diario en Airflow (`entrenamiento_modelos_regresion`):

1. **Carga del dataset** desde un archivo `.pkl` previamente limpiado.
2. **Preprocesamiento**:
   - Encoding de variables categÃ³ricas (`TargetEncoder` para marca, tipo, etc.).
   - ImputaciÃ³n o mapeo de variables binarias (`TransmisiÃ³n`).
3. **Entrenamiento de modelos**:
   - `RandomForestRegressor`
   - `CatBoostRegressor`
   - `SVR`
4. **EvaluaciÃ³n con MAE** y registro de mÃ©tricas en MLflow.
5. **PromociÃ³n automÃ¡tica** del mejor modelo al stage "Production".
6. **TransiciÃ³n del modelo anterior a "Staging"** si existe.

## ğŸ” EjecuciÃ³n

### 1. Clonar el repositorio
```bash
git clone --llenar--
cd --llenar--
```
# 2. Crear y dar permisos a los volÃºmenes
```bash
mkdir -p mlruns
sudo chown -R 50000:0 mlruns
```

# 3. Levantar el entorno completo
```bash
docker-compose up --build -d
```
Para detenerlo:
```Bash
docker compose down
```

Para detenerlo y eliminar todo:
```Bash
docker compose down --rmi all --volumes
```

# 44. Acceder a interfaces
Airflow UI: http://localhost:8080

MLflow UI: http://localhost:5000


```Bash
docker compose up
```

### Para editar desde VSC: sudo chown -R federico:federico /home/federico/Proyectos/CEIA/MLops1/
### Si da error de escritura sobre el path: sudo chown -R 50000:0 ./mlruns
